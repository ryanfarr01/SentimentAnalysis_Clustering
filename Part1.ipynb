{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from matplotlib import pylab as plt\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def get_data(filename):\n",
    "    data_train = []\n",
    "    data_test = []\n",
    "    labels_train = []\n",
    "    labels_test = []\n",
    "    num_p_labels = 0\n",
    "    num_n_labels = 0\n",
    "    for line in open(filename):\n",
    "        l = line[-2]\n",
    "        d = process_line(line[:len(line)-3])\n",
    "        is_positive = l == '1'\n",
    "        is_negative = l == '0'\n",
    "        if is_positive:\n",
    "            num_p_labels += 1\n",
    "            if num_p_labels <= 400:\n",
    "                data_train.append(d)\n",
    "                labels_train.append(l)\n",
    "            else:\n",
    "                data_test.append(d)\n",
    "                labels_test.append(l)\n",
    "        elif is_negative:\n",
    "            num_n_labels += 1\n",
    "            if num_n_labels <= 400:\n",
    "                data_train.append(d)\n",
    "                labels_train.append(l)\n",
    "            else:\n",
    "                data_test.append(d)\n",
    "                labels_test.append(l)\n",
    "        else:\n",
    "            raise Exception('Bad label found')\n",
    "\n",
    "    print('Positive labels: {0}'.format(num_p_labels))\n",
    "    print('Negative labels: {0}'.format(num_n_labels))\n",
    "    return np.array(data_train), np.array(labels_train),\\\n",
    "           np.array(data_test), np.array(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_line(line):\n",
    "    l = line.lower()\n",
    "    l = re.sub(\"[^a-z0-9 ]\", \"\", l) # get rid of everything that isn't a letter or number\n",
    "    \n",
    "    # get all of the words\n",
    "    word_tokens = nltk.word_tokenize(l)\n",
    "    ret_l = ''\n",
    "    for word in word_tokens:\n",
    "        if word not in stop_words: # get rid of stopwords\n",
    "            ret_l += lemmatizer.lemmatize(word) + ' ' # lemmatize\n",
    "\n",
    "    ret_l = ret_l[:len(ret_l)-1] # get rid of the trailing space\n",
    "    return ret_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Positive labels: 500\n",
      "Negative labels: 500\n",
      "Positive labels: 500\n",
      "Negative labels: 500\n",
      "Positive labels: 500\n",
      "Negative labels: 500\n",
      "\n",
      "Training data: 2400\n",
      "Testing data: 600\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "am_trd, am_trl, am_ted, am_tld = get_data('./sentiment labelled sentences/amazon_cells_labelled.txt')\n",
    "im_trd, im_trl, im_ted, im_tld = get_data('./sentiment labelled sentences/imdb_labelled.txt')\n",
    "ye_trd, ye_trl, ye_ted, ye_tld = get_data('./sentiment labelled sentences/yelp_labelled.txt')\n",
    "\n",
    "print('')\n",
    "print('Training data: {0}'.format(len(am_trd) + len(im_trd) + len(ye_trd)))\n",
    "print('Testing data: {0}'.format(len(am_ted) + len(im_ted) + len(ye_ted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 4248\n"
     ]
    }
   ],
   "source": [
    "features = {}\n",
    "def gather_features(d1, d2, d3):\n",
    "    for ds in (d1, d2, d3):\n",
    "        for d in ds:\n",
    "            sl = d.split(' ')\n",
    "            for word in sl:\n",
    "                if word not in features:\n",
    "                    features[word] = len(features)\n",
    "                \n",
    "gather_features(am_trd, im_trd, ye_trd)\n",
    "print('Number of features: {0}'.format(len(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_bag_of_words(data):\n",
    "    ret = []\n",
    "    for d in data:\n",
    "        bow = np.zeros(len(features))\n",
    "        line = d.split(' ')\n",
    "        for word in line:\n",
    "            if word in features:\n",
    "                bow[features[word]] += 1\n",
    "        ret.append(bow)\n",
    "    return np.array(ret)\n",
    "\n",
    "amc_trd = convert_bag_of_words(am_trd)\n",
    "amc_ted = convert_bag_of_words(am_ted)\n",
    "imc_trd = convert_bag_of_words(im_trd)\n",
    "imc_ted = convert_bag_of_words(im_ted)\n",
    "yec_trd = convert_bag_of_words(ye_trd)\n",
    "yec_ted = convert_bag_of_words(ye_ted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Part 1.E\n",
    "\"\"\"\n",
    "def postprocess(train1, train2, train3, test1, test2, test3):\n",
    "    mean = get_mean(train1, train2, train3)\n",
    "    var = get_variance(train1, train2, train3)\n",
    "    \n",
    "    t1 = []\n",
    "    t2 = []\n",
    "    t3 = []\n",
    "    te1 = []\n",
    "    te2 = []\n",
    "    te3 = []\n",
    "    for o,n in [(train1, t1), (train2, t2), (train3, t3), (test1, te1), (test2, te2), (test3, te3)]:\n",
    "        for d in o:\n",
    "            n.append((d-mean)/var)\n",
    "    return np.array(t1), np.array(t2), np.array(t3), np.array(te1), np.array(te2), np.array(te3)\n",
    "\n",
    "def get_mean(d1, d2, d3):\n",
    "    all_data = np.concatenate((d1, d2, d3))\n",
    "    return np.mean(all_data, axis=0)\n",
    "\n",
    "def get_variance(d1, d2, d3):\n",
    "    all_data = np.concatenate((d1, d2, d3))\n",
    "    return np.var(all_data, axis=0)\n",
    "\n",
    "amp_trd, imp_trd, yep_trd, amp_ted, imp_ted, yep_ted = postprocess(amc_trd, imc_trd, yec_trd, amc_ted, imc_ted, yec_ted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive: 188.0\n",
      "False Positive: 73.0\n",
      "True Negative: 227.0\n",
      "False Negative: 112.0\n",
      "Accuracy: 0.691666666667\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Part 1.F\n",
    "\"\"\"\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def classify_logistic_regression(training_set, training_labels, testing_set, testing_labels):\n",
    "    tp = 0.0\n",
    "    tn = 0.0\n",
    "    fp = 0.0\n",
    "    fn = 0.0\n",
    "    \n",
    "    lr = LogisticRegression().fit(training_set, training_labels)\n",
    "    guesses = lr.predict(testing_set)\n",
    "    for ind in xrange(len(guesses)):\n",
    "        label = guesses[ind]\n",
    "        tl = testing_labels[ind]\n",
    "        correct = tl == label\n",
    "        if label == '1':\n",
    "            if correct: tp += 1.0\n",
    "            else: fp += 1.0\n",
    "        else:\n",
    "            if correct: tn += 1.0\n",
    "            else: fn += 1.0\n",
    "            \n",
    "    print(\"True Positive: {0}\".format(tp))\n",
    "    print(\"False Positive: {0}\".format(fp))    \n",
    "    print(\"True Negative: {0}\".format(tn))    \n",
    "    print(\"False Negative: {0}\".format(fn))    \n",
    "    print(\"Accuracy: {0}\".format((tp + tn)/(tp + tn + fp + fn)))\n",
    "\n",
    "classify_logistic_regression(np.concatenate((amp_trd, imp_trd, yep_trd)), \n",
    "                             np.concatenate((am_trl, im_trl, ye_trl)),\n",
    "                             np.concatenate((amp_ted, imp_ted, yep_ted)),\n",
    "                             np.concatenate((am_tld, im_tld, ye_tld)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive: 140.0\n",
      "False Positive: 57.0\n",
      "True Negative: 243.0\n",
      "False Negative: 160.0\n",
      "Accuracy: 0.638333333333\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Part 1.F\n",
    "\"\"\"\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "def classify_naive_bayes(training_set, training_labels, testing_set, testing_labels):\n",
    "    tp = 0.0\n",
    "    tn = 0.0\n",
    "    fp = 0.0\n",
    "    fn = 0.0\n",
    "    \n",
    "    nb = GaussianNB().fit(training_set, training_labels)\n",
    "    guesses = nb.predict(testing_set)\n",
    "    for ind in xrange(len(guesses)):\n",
    "        label = guesses[ind]\n",
    "        tl = testing_labels[ind]\n",
    "        correct = tl == label\n",
    "        if label == '1':\n",
    "            if correct: tp += 1.0\n",
    "            else: fp += 1.0\n",
    "        else:\n",
    "            if correct: tn += 1.0\n",
    "            else: fn += 1.0\n",
    "            \n",
    "    print(\"True Positive: {0}\".format(tp))\n",
    "    print(\"False Positive: {0}\".format(fp))    \n",
    "    print(\"True Negative: {0}\".format(tn))    \n",
    "    print(\"False Negative: {0}\".format(fn))    \n",
    "    print(\"Accuracy: {0}\".format((tp + tn)/(tp + tn + fp + fn)))\n",
    "\n",
    "classify_naive_bayes(np.concatenate((amp_trd, imp_trd, yep_trd)), \n",
    "                             np.concatenate((am_trl, im_trl, ye_trl)),\n",
    "                             np.concatenate((amp_ted, imp_ted, yep_ted)),\n",
    "                             np.concatenate((am_tld, im_tld, ye_tld)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
