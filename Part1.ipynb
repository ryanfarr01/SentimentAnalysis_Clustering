{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "from matplotlib import pylab as plt\n",
    "\n",
    "stop_words = {'the', 'and', 'or', 'with', 'its', \"it's\"}\n",
    "\n",
    "def get_data(filename):\n",
    "    data_train = []\n",
    "    data_test = []\n",
    "    labels_train = []\n",
    "    labels_test = []\n",
    "    num_p_labels = 0\n",
    "    num_n_labels = 0\n",
    "    for line in open(filename):\n",
    "        l = line[-2]\n",
    "        d = process_line(line[:len(line)-3])\n",
    "        is_positive = l == '1'\n",
    "        is_negative = l == '0'\n",
    "        if is_positive:\n",
    "            num_p_labels += 1\n",
    "            if num_p_labels <= 400:\n",
    "                data_train.append(d)\n",
    "                labels_train.append(l)\n",
    "            else:\n",
    "                data_test.append(d)\n",
    "                labels_test.append(l)\n",
    "        elif is_negative:\n",
    "            num_n_labels += 1\n",
    "            if num_n_labels <= 400:\n",
    "                data_train.append(d)\n",
    "                labels_train.append(l)\n",
    "            else:\n",
    "                data_test.append(d)\n",
    "                labels_test.append(l)\n",
    "        else:\n",
    "            raise Exception('Bad label found')\n",
    "\n",
    "    print('Positive labels: {0}'.format(num_p_labels))\n",
    "    print('Negative labels: {0}'.format(num_n_labels))\n",
    "    return np.array(data_train), np.array(labels_train),\\\n",
    "           np.array(data_test), np.array(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def process_line(line):\n",
    "    l = line.lower()\n",
    "    l = l.translate(None, string.punctuation)\n",
    "    \n",
    "    # get all of the words\n",
    "    word_tokens = l.split(' ')\n",
    "    ret_l = ''\n",
    "    for word in word_tokens:\n",
    "        if word not in stop_words: # get rid of stopwords\n",
    "            ret_l += word + ' '\n",
    "\n",
    "    ret_l = ret_l[:len(ret_l)-1] # get rid of the trailing space\n",
    "    return ret_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Positive labels: 500\n",
      "Negative labels: 500\n",
      "Positive labels: 500\n",
      "Negative labels: 500\n",
      "Positive labels: 500\n",
      "Negative labels: 500\n",
      "\n",
      "Training data: 2400\n",
      "Testing data: 600\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "am_trd, am_trl, am_ted, am_tld = get_data('./sentiment labelled sentences/amazon_cells_labelled.txt')\n",
    "im_trd, im_trl, im_ted, im_tld = get_data('./sentiment labelled sentences/imdb_labelled.txt')\n",
    "ye_trd, ye_trl, ye_ted, ye_tld = get_data('./sentiment labelled sentences/yelp_labelled.txt')\n",
    "\n",
    "print('')\n",
    "print('Training data: {0}'.format(len(am_trd) + len(im_trd) + len(ye_trd)))\n",
    "print('Testing data: {0}'.format(len(am_ted) + len(im_ted) + len(ye_ted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 4706\n"
     ]
    }
   ],
   "source": [
    "def gather_features(feature_map, d1, d2, d3):\n",
    "    for ds in (d1, d2, d3):\n",
    "        for d in ds:\n",
    "            sl = d.split(' ')\n",
    "            for word in sl:\n",
    "                if word not in feature_map:\n",
    "                    feature_map[word] = len(features)\n",
    "                \n",
    "features = {}\n",
    "gather_features(features, am_trd, im_trd, ye_trd)\n",
    "print('Number of features: {0}'.format(len(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bag_of_words(feature_set, data):\n",
    "    ret = []\n",
    "    for d in data:\n",
    "        bow = np.zeros(len(feature_set))\n",
    "        line = d.split(' ')\n",
    "        for word in line:\n",
    "            if word in features:\n",
    "                bow[feature_set[word]] += 1\n",
    "        ret.append(bow)\n",
    "    return np.array(ret)\n",
    "\n",
    "amc_trd = convert_bag_of_words(features, am_trd)\n",
    "amc_ted = convert_bag_of_words(features, am_ted)\n",
    "imc_trd = convert_bag_of_words(features, im_trd)\n",
    "imc_ted = convert_bag_of_words(features, im_ted)\n",
    "yec_trd = convert_bag_of_words(features, ye_trd)\n",
    "yec_ted = convert_bag_of_words(features, ye_ted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Part 1.E\n",
    "\"\"\"\n",
    "def postprocess(train1, train2, train3, test1, test2, test3):\n",
    "    return train1, train2, train3, test1, test2, test3\n",
    "    mean = get_mean(train1, train2, train3)\n",
    "    var = get_variance(train1, train2, train3)\n",
    "    \n",
    "    t1 = []\n",
    "    t2 = []\n",
    "    t3 = []\n",
    "    te1 = []\n",
    "    te2 = []\n",
    "    te3 = []\n",
    "    for o,n in [(train1, t1), (train2, t2), (train3, t3), (test1, te1), (test2, te2), (test3, te3)]:\n",
    "        for d in o:\n",
    "            n.append((d-mean)/var)\n",
    "    return np.array(t1), np.array(t2), np.array(t3), np.array(te1), np.array(te2), np.array(te3)\n",
    "\n",
    "def get_mean(d1, d2, d3):\n",
    "    all_data = np.concatenate((d1, d2, d3))\n",
    "    return np.mean(all_data, axis=0)\n",
    "\n",
    "def get_variance(d1, d2, d3):\n",
    "    all_data = np.concatenate((d1, d2, d3))\n",
    "    return np.var(all_data, axis=0)\n",
    "\n",
    "amp_trd, imp_trd, yep_trd, amp_ted, imp_ted, yep_ted = postprocess(amc_trd, imc_trd, yec_trd, amc_ted, imc_ted, yec_ted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive: 238.0\n",
      "False Positive: 45.0\n",
      "True Negative: 255.0\n",
      "False Negative: 62.0\n",
      "Accuracy: 0.821666666667\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Part 1.F\n",
    "\"\"\"\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def classify_logistic_regression(training_set, training_labels, testing_set, testing_labels):\n",
    "    tp = 0.0\n",
    "    tn = 0.0\n",
    "    fp = 0.0\n",
    "    fn = 0.0\n",
    "    \n",
    "    lr = LogisticRegression().fit(training_set, training_labels)\n",
    "    guesses = lr.predict(testing_set)\n",
    "    for ind in xrange(len(guesses)):\n",
    "        label = guesses[ind]\n",
    "        tl = testing_labels[ind]\n",
    "        correct = tl == label\n",
    "        if label == '1':\n",
    "            if correct: tp += 1.0\n",
    "            else: fp += 1.0\n",
    "        else:\n",
    "            if correct: tn += 1.0\n",
    "            else: fn += 1.0\n",
    "            \n",
    "    print(\"True Positive: {0}\".format(tp))\n",
    "    print(\"False Positive: {0}\".format(fp))    \n",
    "    print(\"True Negative: {0}\".format(tn))    \n",
    "    print(\"False Negative: {0}\".format(fn))    \n",
    "    print(\"Accuracy: {0}\".format((tp + tn)/(tp + tn + fp + fn)))\n",
    "\n",
    "classify_logistic_regression(np.concatenate((amp_trd, imp_trd, yep_trd)), \n",
    "                             np.concatenate((am_trl, im_trl, ye_trl)),\n",
    "                             np.concatenate((amp_ted, imp_ted, yep_ted)),\n",
    "                             np.concatenate((am_tld, im_tld, ye_tld)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive: 154.0\n",
      "False Positive: 39.0\n",
      "True Negative: 261.0\n",
      "False Negative: 146.0\n",
      "Accuracy: 0.691666666667\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Part 1.F\n",
    "\"\"\"\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "def classify_naive_bayes(training_set, training_labels, testing_set, testing_labels):\n",
    "    tp = 0.0\n",
    "    tn = 0.0\n",
    "    fp = 0.0\n",
    "    fn = 0.0\n",
    "    \n",
    "    nb = GaussianNB().fit(training_set, training_labels)\n",
    "    guesses = nb.predict(testing_set)\n",
    "    for ind in xrange(len(guesses)):\n",
    "        label = guesses[ind]\n",
    "        tl = testing_labels[ind]\n",
    "        correct = tl == label\n",
    "        if label == '1':\n",
    "            if correct: tp += 1.0\n",
    "            else: fp += 1.0\n",
    "        else:\n",
    "            if correct: tn += 1.0\n",
    "            else: fn += 1.0\n",
    "            \n",
    "    print(\"True Positive: {0}\".format(tp))\n",
    "    print(\"False Positive: {0}\".format(fp))    \n",
    "    print(\"True Negative: {0}\".format(tn))    \n",
    "    print(\"False Negative: {0}\".format(fn))    \n",
    "    print(\"Accuracy: {0}\".format((tp + tn)/(tp + tn + fp + fn)))\n",
    "\n",
    "classify_naive_bayes(np.concatenate((amp_trd, imp_trd, yep_trd)), \n",
    "                     np.concatenate((am_trl, im_trl, ye_trl)),\n",
    "                     np.concatenate((amp_ted, imp_ted, yep_ted)),\n",
    "                     np.concatenate((am_tld, im_tld, ye_tld)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14438\n",
      "\n",
      "Logistic Regression:\n",
      "True Positive: 220.0\n",
      "False Positive: 123.0\n",
      "True Negative: 177.0\n",
      "False Negative: 80.0\n",
      "Accuracy: 0.661666666667\n",
      "\n",
      "Naive Bayes:\n",
      "True Positive: 247.0\n",
      "False Positive: 166.0\n",
      "True Negative: 134.0\n",
      "False Negative: 53.0\n",
      "Accuracy: 0.635\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Part 1.G\n",
    "\"\"\"\n",
    "def get_2_grams(line):\n",
    "    ret = []\n",
    "    words = line.split(' ')\n",
    "    if len(words) == 0: return []\n",
    "    if len(words) == 1: return words\n",
    "    \n",
    "    w1 = words[0]\n",
    "    w2 = words[1]\n",
    "    for i in xrange(3, len(words)):\n",
    "        new_word = w1 + ' ' + w2\n",
    "        ret.append(new_word)\n",
    "        w1 = words[i-2]\n",
    "        w2 = words[i-1]\n",
    "    return ret\n",
    "\n",
    "def get_2_gram_features(feature_set, data):\n",
    "    for d in data:\n",
    "        for p in get_2_grams(d):\n",
    "            if p not in feature_set:\n",
    "                feature_set[p] = len(feature_set)\n",
    "    \n",
    "def convert_2_gram(feature_set, data):\n",
    "    ret = []\n",
    "    for d in data:\n",
    "        gram = np.zeros(len(feature_set))\n",
    "        for p in get_2_grams(d):\n",
    "            if p in feature_set:\n",
    "                gram[feature_set[p]] += 1\n",
    "        ret.append(gram)\n",
    "    return np.array(ret)\n",
    "\n",
    "two_gram_features = {}\n",
    "get_2_gram_features(two_gram_features, np.concatenate((am_trd, im_trd, ye_trd)))\n",
    "print(len(two_gram_features))\n",
    "\n",
    "amg_trd = convert_2_gram(two_gram_features, am_trd)\n",
    "amg_ted = convert_2_gram(two_gram_features, am_ted)\n",
    "img_trd = convert_2_gram(two_gram_features, im_trd)\n",
    "img_ted = convert_2_gram(two_gram_features, im_ted)\n",
    "yeg_trd = convert_2_gram(two_gram_features, ye_trd)\n",
    "yeg_ted = convert_2_gram(two_gram_features, ye_ted)\n",
    "\n",
    "print('\\r\\nLogistic Regression:')\n",
    "classify_logistic_regression(np.concatenate((amg_trd, img_trd, yeg_trd)), \n",
    "                             np.concatenate((am_trl, im_trl, ye_trl)),\n",
    "                             np.concatenate((amg_ted, img_ted, yeg_ted)),\n",
    "                             np.concatenate((am_tld, im_tld, ye_tld)))\n",
    "\n",
    "print('\\r\\nNaive Bayes:')\n",
    "classify_naive_bayes(np.concatenate((amg_trd, img_trd, yeg_trd)), \n",
    "                     np.concatenate((am_trl, im_trl, ye_trl)),\n",
    "                     np.concatenate((amg_ted, img_ted, yeg_ted)),\n",
    "                     np.concatenate((am_tld, im_tld, ye_tld)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PCA rank 10:\n",
      "True Positive: 171.0\n",
      "False Positive: 157.0\n",
      "True Negative: 143.0\n",
      "False Negative: 129.0\n",
      "Accuracy: 0.523333333333\n",
      "\n",
      "PCA rank 50:\n",
      "True Positive: 191.0\n",
      "False Positive: 81.0\n",
      "True Negative: 219.0\n",
      "False Negative: 109.0\n",
      "Accuracy: 0.683333333333\n",
      "\n",
      "PCA rank 100:\n",
      "True Positive: 191.0\n",
      "False Positive: 70.0\n",
      "True Negative: 230.0\n",
      "False Negative: 109.0\n",
      "Accuracy: 0.701666666667\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Part 1.H\n",
    "\"\"\"\n",
    "from numpy.linalg import svd\n",
    "\n",
    "def pca(rank, t1, t2, t3, te1, te2, te3):\n",
    "    U, E, Vt = svd(np.concatenate((t1, t2, t3, te1, te2, te3)),\n",
    "                   full_matrices=True)\n",
    "    E = np.diag(E)\n",
    "    \n",
    "    Tk = U[:,:rank].dot(E[:rank,:rank])\n",
    "    t1r = Tk[:800,:]\n",
    "    t2r = Tk[800:1600,:]\n",
    "    t3r = Tk[1600:2400,:]\n",
    "    te1r = Tk[2400:2600,:]\n",
    "    te2r = Tk[2600:2800,:]\n",
    "    te3r = Tk[2800:3000,:]\n",
    "    \n",
    "    return t1r, t2r, t3r, te1r, te2r, te3r\n",
    "\n",
    "for rank in (10, 50, 100):\n",
    "    print('\\r\\nPCA rank {0}:'.format(rank))\n",
    "    t1r, t2r, t3r, te1r, te2r, te3r = pca(rank, amp_trd, imp_trd, yep_trd,\n",
    "                                          amp_ted, imp_ted, yep_ted)\n",
    "\n",
    "    classify_logistic_regression(np.concatenate((t1r, t2r, t3r)), \n",
    "                                 np.concatenate((am_trl, im_trl, ye_trl)),\n",
    "                                 np.concatenate((te1r, te2r, te3r)),\n",
    "                                 np.concatenate((am_tld, im_tld, ye_tld)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
