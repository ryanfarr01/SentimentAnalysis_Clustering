{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from matplotlib import pylab as plt\n",
    "\n",
    "stop_words = {'the', 'and', 'or', 'with', 'its', \"it's\"}\n",
    "\n",
    "def get_data(filename):\n",
    "    data_train = []\n",
    "    data_test = []\n",
    "    labels_train = []\n",
    "    labels_test = []\n",
    "    num_p_labels = 0\n",
    "    num_n_labels = 0\n",
    "    for line in open(filename):\n",
    "        l = line[-2]\n",
    "        d = process_line(line[:len(line)-3])\n",
    "        is_positive = l == '1'\n",
    "        is_negative = l == '0'\n",
    "        if is_positive:\n",
    "            num_p_labels += 1\n",
    "            if num_p_labels <= 400:\n",
    "                data_train.append(d)\n",
    "                labels_train.append(l)\n",
    "            else:\n",
    "                data_test.append(d)\n",
    "                labels_test.append(l)\n",
    "        elif is_negative:\n",
    "            num_n_labels += 1\n",
    "            if num_n_labels <= 400:\n",
    "                data_train.append(d)\n",
    "                labels_train.append(l)\n",
    "            else:\n",
    "                data_test.append(d)\n",
    "                labels_test.append(l)\n",
    "        else:\n",
    "            raise Exception('Bad label found')\n",
    "\n",
    "    print('Positive labels: {0}'.format(num_p_labels))\n",
    "    print('Negative labels: {0}'.format(num_n_labels))\n",
    "    return np.array(data_train), np.array(labels_train),\\\n",
    "           np.array(data_test), np.array(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def process_line(line):\n",
    "    l = line.lower()\n",
    "    l = l.translate(None, string.punctuation)\n",
    "    \n",
    "    # get all of the words\n",
    "    word_tokens = l.split(' ')\n",
    "    ret_l = ''\n",
    "    for word in word_tokens:\n",
    "        if word not in stop_words: # get rid of stopwords\n",
    "            ret_l += word + ' '\n",
    "\n",
    "    ret_l = ret_l[:len(ret_l)-1] # get rid of the trailing space\n",
    "    return ret_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Positive labels: 500\n",
      "Negative labels: 500\n",
      "Positive labels: 500\n",
      "Negative labels: 500\n",
      "Positive labels: 500\n",
      "Negative labels: 500\n",
      "\n",
      "Training data: 2400\n",
      "Testing data: 600\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "am_trd, am_trl, am_ted, am_tld = get_data('./sentiment labelled sentences/amazon_cells_labelled.txt')\n",
    "im_trd, im_trl, im_ted, im_tld = get_data('./sentiment labelled sentences/imdb_labelled.txt')\n",
    "ye_trd, ye_trl, ye_ted, ye_tld = get_data('./sentiment labelled sentences/yelp_labelled.txt')\n",
    "\n",
    "print('')\n",
    "print('Training data: {0}'.format(len(am_trd) + len(im_trd) + len(ye_trd)))\n",
    "print('Testing data: {0}'.format(len(am_ted) + len(im_ted) + len(ye_ted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 4706\n"
     ]
    }
   ],
   "source": [
    "index_to_word = {}\n",
    "def gather_features(feature_map, d1, d2, d3):\n",
    "    for ds in (d1, d2, d3):\n",
    "        for d in ds:\n",
    "            sl = d.split(' ')\n",
    "            for word in sl:\n",
    "                if word not in feature_map:\n",
    "                    ind = len(features)\n",
    "                    feature_map[word] = ind\n",
    "                    index_to_word[ind] = word\n",
    "                \n",
    "features = {}\n",
    "gather_features(features, am_trd, im_trd, ye_trd)\n",
    "print('Number of features: {0}'.format(len(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bag_of_words(feature_set, data):\n",
    "    ret = []\n",
    "    for d in data:\n",
    "        bow = np.zeros(len(feature_set))\n",
    "        line = d.split(' ')\n",
    "        for word in line:\n",
    "            if word in features:\n",
    "                bow[feature_set[word]] += 1\n",
    "        ret.append(bow)\n",
    "    return np.array(ret)\n",
    "\n",
    "amc_trd = convert_bag_of_words(features, am_trd)\n",
    "amc_ted = convert_bag_of_words(features, am_ted)\n",
    "imc_trd = convert_bag_of_words(features, im_trd)\n",
    "imc_ted = convert_bag_of_words(features, im_ted)\n",
    "yec_trd = convert_bag_of_words(features, ye_trd)\n",
    "yec_ted = convert_bag_of_words(features, ye_ted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Part 1.E\n",
    "\"\"\"\n",
    "def postprocess(train1, train2, train3, test1, test2, test3):\n",
    "    return train1, train2, train3, test1, test2, test3\n",
    "\n",
    "amp_trd, imp_trd, yep_trd, amp_ted, imp_ted, yep_ted = postprocess(amc_trd, imc_trd, yec_trd, amc_ted, imc_ted, yec_ted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 weighted words: \n",
      "reviewing\n",
      "reasons\n",
      "liking\n",
      "2mp\n",
      "pics\n",
      "True Positive: 238.0\n",
      "False Positive: 45.0\n",
      "True Negative: 255.0\n",
      "False Negative: 62.0\n",
      "Accuracy: 0.821666666667\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Part 1.F\n",
    "\"\"\"\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def classify_logistic_regression(training_set, training_labels, testing_set, testing_labels, ind_to_words=None, print_top_words=True):\n",
    "    tp = 0.0\n",
    "    tn = 0.0\n",
    "    fp = 0.0\n",
    "    fn = 0.0\n",
    "    \n",
    "    lr = LogisticRegression().fit(training_set, training_labels)\n",
    "    guesses = lr.predict(testing_set)\n",
    "    for ind in xrange(len(guesses)):\n",
    "        label = guesses[ind]\n",
    "        tl = testing_labels[ind]\n",
    "        correct = tl == label\n",
    "        if label == '1':\n",
    "            if correct: tp += 1.0\n",
    "            else: fp += 1.0\n",
    "        else:\n",
    "            if correct: tn += 1.0\n",
    "            else: fn += 1.0\n",
    "    \n",
    "    if print_top_words:\n",
    "        weight_vector = np.abs(lr.coef_)\n",
    "        sorted_index = np.argsort(weight_vector)[::-1]\n",
    "        print('Top 5 weighted words: ')\n",
    "        for i in range(5):\n",
    "            print ind_to_words[sorted_index[0][i]]\n",
    "    \n",
    "    print(\"True Positive: {0}\".format(tp))\n",
    "    print(\"False Positive: {0}\".format(fp))    \n",
    "    print(\"True Negative: {0}\".format(tn))    \n",
    "    print(\"False Negative: {0}\".format(fn))    \n",
    "    print(\"Accuracy: {0}\".format((tp + tn)/(tp + tn + fp + fn)))\n",
    "\n",
    "classify_logistic_regression(np.concatenate((amp_trd, imp_trd, yep_trd)), \n",
    "                             np.concatenate((am_trl, im_trl, ye_trl)),\n",
    "                             np.concatenate((amp_ted, imp_ted, yep_ted)),\n",
    "                             np.concatenate((am_tld, im_tld, ye_tld)), index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive: 154.0\n",
      "False Positive: 39.0\n",
      "True Negative: 261.0\n",
      "False Negative: 146.0\n",
      "Accuracy: 0.691666666667\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Part 1.F\n",
    "\"\"\"\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "def classify_naive_bayes(training_set, training_labels, testing_set, testing_labels):\n",
    "    tp = 0.0\n",
    "    tn = 0.0\n",
    "    fp = 0.0\n",
    "    fn = 0.0\n",
    "    \n",
    "    nb = GaussianNB().fit(training_set, training_labels)\n",
    "    guesses = nb.predict(testing_set)\n",
    "    for ind in xrange(len(guesses)):\n",
    "        label = guesses[ind]\n",
    "        tl = testing_labels[ind]\n",
    "        correct = tl == label\n",
    "        if label == '1':\n",
    "            if correct: tp += 1.0\n",
    "            else: fp += 1.0\n",
    "        else:\n",
    "            if correct: tn += 1.0\n",
    "            else: fn += 1.0\n",
    "            \n",
    "    print(\"True Positive: {0}\".format(tp))\n",
    "    print(\"False Positive: {0}\".format(fp))    \n",
    "    print(\"True Negative: {0}\".format(tn))    \n",
    "    print(\"False Negative: {0}\".format(fn))    \n",
    "    print(\"Accuracy: {0}\".format((tp + tn)/(tp + tn + fp + fn)))\n",
    "\n",
    "classify_naive_bayes(np.concatenate((amp_trd, imp_trd, yep_trd)), \n",
    "                     np.concatenate((am_trl, im_trl, ye_trl)),\n",
    "                     np.concatenate((amp_ted, imp_ted, yep_ted)),\n",
    "                     np.concatenate((am_tld, im_tld, ye_tld)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14438\n",
      "\n",
      "Logistic Regression:\n",
      "Top 5 weighted words: \n",
      "tell you\n",
      "not having\n",
      "his most\n",
      "who is\n",
      "he came\n",
      "True Positive: 220.0\n",
      "False Positive: 123.0\n",
      "True Negative: 177.0\n",
      "False Negative: 80.0\n",
      "Accuracy: 0.661666666667\n",
      "\n",
      "Naive Bayes:\n",
      "True Positive: 247.0\n",
      "False Positive: 166.0\n",
      "True Negative: 134.0\n",
      "False Negative: 53.0\n",
      "Accuracy: 0.635\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Part 1.G\n",
    "\"\"\"\n",
    "def get_2_grams(line):\n",
    "    ret = []\n",
    "    words = line.split(' ')\n",
    "    if len(words) == 0: return []\n",
    "    if len(words) == 1: return words\n",
    "    \n",
    "    w1 = words[0]\n",
    "    w2 = words[1]\n",
    "    for i in xrange(3, len(words)):\n",
    "        new_word = w1 + ' ' + w2\n",
    "        ret.append(new_word)\n",
    "        w1 = words[i-2]\n",
    "        w2 = words[i-1]\n",
    "    return ret\n",
    "\n",
    "index_to_grams = {}\n",
    "def get_2_gram_features(feature_set, data):\n",
    "    for d in data:\n",
    "        for p in get_2_grams(d):\n",
    "            if p not in feature_set:\n",
    "                ind = len(feature_set)\n",
    "                feature_set[p] = ind\n",
    "                index_to_grams[ind] = p\n",
    "                \n",
    "    \n",
    "def convert_2_gram(feature_set, data):\n",
    "    ret = []\n",
    "    for d in data:\n",
    "        gram = np.zeros(len(feature_set))\n",
    "        for p in get_2_grams(d):\n",
    "            if p in feature_set:\n",
    "                gram[feature_set[p]] += 1\n",
    "        ret.append(gram)\n",
    "    return np.array(ret)\n",
    "\n",
    "two_gram_features = {}\n",
    "get_2_gram_features(two_gram_features, np.concatenate((am_trd, im_trd, ye_trd)))\n",
    "print(len(two_gram_features))\n",
    "\n",
    "amg_trd = convert_2_gram(two_gram_features, am_trd)\n",
    "amg_ted = convert_2_gram(two_gram_features, am_ted)\n",
    "img_trd = convert_2_gram(two_gram_features, im_trd)\n",
    "img_ted = convert_2_gram(two_gram_features, im_ted)\n",
    "yeg_trd = convert_2_gram(two_gram_features, ye_trd)\n",
    "yeg_ted = convert_2_gram(two_gram_features, ye_ted)\n",
    "\n",
    "print('\\r\\nLogistic Regression:')\n",
    "classify_logistic_regression(np.concatenate((amg_trd, img_trd, yeg_trd)), \n",
    "                             np.concatenate((am_trl, im_trl, ye_trl)),\n",
    "                             np.concatenate((amg_ted, img_ted, yeg_ted)),\n",
    "                             np.concatenate((am_tld, im_tld, ye_tld)), index_to_grams)\n",
    "\n",
    "print('\\r\\nNaive Bayes:')\n",
    "classify_naive_bayes(np.concatenate((amg_trd, img_trd, yeg_trd)), \n",
    "                     np.concatenate((am_trl, im_trl, ye_trl)),\n",
    "                     np.concatenate((amg_ted, img_ted, yeg_ted)),\n",
    "                     np.concatenate((am_tld, im_tld, ye_tld)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Vts\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Part 1.H\n",
    "\"\"\"\n",
    "from numpy.linalg import svd\n",
    "\n",
    "def get_Vt(data):\n",
    "    _,_,vt = np.linalg.svd(data, full_matrices=True)\n",
    "    return vt\n",
    "\n",
    "print(\"Getting Vts\")\n",
    "vt_1 = get_Vt(np.concatenate((amp_trd, imp_trd, yep_trd)))\n",
    "vt_2 = get_Vt(np.concatenate((amg_trd, img_trd, yeg_trd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For standard data\n",
      "PCA rank 10:\n",
      "True Positive: 143.0\n",
      "False Positive: 125.0\n",
      "True Negative: 175.0\n",
      "False Negative: 157.0\n",
      "Accuracy: 0.53\n",
      "PCA rank 50:\n",
      "True Positive: 154.0\n",
      "False Positive: 108.0\n",
      "True Negative: 192.0\n",
      "False Negative: 146.0\n",
      "Accuracy: 0.576666666667\n",
      "PCA rank 100:\n",
      "True Positive: 166.0\n",
      "False Positive: 86.0\n",
      "True Negative: 214.0\n",
      "False Negative: 134.0\n",
      "Accuracy: 0.633333333333\n",
      "PCA rank 600:\n",
      "True Positive: 222.0\n",
      "False Positive: 60.0\n",
      "True Negative: 240.0\n",
      "False Negative: 78.0\n",
      "Accuracy: 0.77\n",
      "\n",
      "For N-gram data\n",
      "PCA rank 10:\n",
      "True Positive: 109.0\n",
      "False Positive: 97.0\n",
      "True Negative: 203.0\n",
      "False Negative: 191.0\n",
      "Accuracy: 0.52\n",
      "PCA rank 50:\n",
      "True Positive: 120.0\n",
      "False Positive: 116.0\n",
      "True Negative: 184.0\n",
      "False Negative: 180.0\n",
      "Accuracy: 0.506666666667\n",
      "PCA rank 100:\n",
      "True Positive: 132.0\n",
      "False Positive: 107.0\n",
      "True Negative: 193.0\n",
      "False Negative: 168.0\n",
      "Accuracy: 0.541666666667\n",
      "PCA rank 600:\n",
      "True Positive: 212.0\n",
      "False Positive: 151.0\n",
      "True Negative: 149.0\n",
      "False Negative: 88.0\n",
      "Accuracy: 0.601666666667\n"
     ]
    }
   ],
   "source": [
    "def pca(rank, Vt, data):\n",
    "    return data.dot(Vt[:,:rank])\n",
    "\n",
    "d1 = [amp_trd, imp_trd, yep_trd, amp_ted, imp_ted, yep_ted]\n",
    "d2 = [amg_trd, img_trd, yeg_trd, amg_ted, img_ted, yeg_ted]\n",
    "for Vt, message, ds in [(vt_1, '\\r\\nFor standard data', d1),(vt_2, '\\r\\nFor N-gram data', d2)]:\n",
    "    print(message)\n",
    "    for rank in (10, 50, 100, 600):\n",
    "        print('PCA rank {0}:'.format(rank))\n",
    "        t1r = pca(rank, Vt, ds[0])\n",
    "        t2r = pca(rank, Vt, ds[1])\n",
    "        t3r = pca(rank, Vt, ds[2])\n",
    "        te1r = pca(rank, Vt, ds[3])\n",
    "        te2r = pca(rank, Vt, ds[4])\n",
    "        te3r = pca(rank, Vt, ds[5])\n",
    "\n",
    "        classify_logistic_regression(np.concatenate((t1r, t2r, t3r)), \n",
    "                                     np.concatenate((am_trl, im_trl, ye_trl)),\n",
    "                                     np.concatenate((te1r, te2r, te3r)),\n",
    "                                     np.concatenate((am_tld, im_tld, ye_tld)), None, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
